# ü§ñ ClientaTech AI Agent

O **ClientaTech AI Agent** √© um assistente inteligente baseado em SQL e LLMs locais (via Ollama), projetado para analisar dados de clientes, contratos e intera√ß√µes. Ele utiliza uma arquitetura de roteamento sem√¢ntico para classificar a inten√ß√£o do usu√°rio (Perfil, Risco, Hist√≥rico, etc.) e gerar consultas SQL precisas apenas quando necess√°rio.

---

## üìÇ Estrutura do Projeto

O projeto foi reorganizado para melhor modularidade:

*   **`src/`**: C√≥digo fonte principal da aplica√ß√£o.
    *   `agent.py`: O "c√©rebro" do agente. Cont√©m a l√≥gica de conex√£o com LLM, Roteador Sem√¢ntico e geradores SQL.
    *   `app_ui.py`: Interface Web interativa constru√≠da com **Streamlit**.
*   **`database/`**: Scripts de configura√ß√£o e arquivos do banco de dados principal.
    *   `clientatech.db` / `clientatech_v2.db`: Banco de dados SQLite simulando o CRM.
    *   `setup_database.py`: Script para recriar o banco de dados com dados fict√≠cios.
*   **`data/`**: Arquivos de dados auxiliares e cache.
    *   `cache.db`: Cache sem√¢ntico para evitar chamadas repetitivas ao LLM/Banco.
*   **`finetuning/`**: Datasets e scripts para treinamento/ajuste de modelos.
    *   `dataset_finetuning.jsonl`: Arquivo de exemplos (Few-Shot/Fine-tuning).
    *   `generate_dataset.py`: Script gerador de datasets sint√©ticos.
*   **`logs/`**: Logs de execu√ß√£o do sistema.
    *   `agent.log`: Registro de atividades, erros e debug.

---

## üöÄ Como Executar

### 1. Pr√©-requisitos

*   **Python 3.8+** (Para execu√ß√£o local sem Docker)
*   **Docker & Docker Compose** (Recomendado)
*   **Ollama** instalado no host e rodando com o modelo `qwen2.5-coder:14b`.

### 2. Configura√ß√£o do Banco de Dados

Antes de rodar, gere o banco de dados de teste:

```bash
python database/setup_database.py
```

### 3. Rodando com Docker (Recomendado)

A aplica√ß√£o foi dockerizada para facilitar a execu√ß√£o da interface web.

1.  **Inicie o container:**

```bash
docker-compose up --build
```

2.  Acesse a aplica√ß√£o no navegador em: `http://localhost:8502`

> **Nota:** O Docker est√° configurado para se conectar ao Ollama rodando na sua m√°quina local ("host"). Certifique-se de que o Ollama est√° rodando (`ollama serve`).

### 4. Rodando Manualmente (Sem Docker)

1.  Instale as depend√™ncias:
    ```bash
    pip install -r requirements.txt
    ```

2.  Execute a Interface Web:
    ```bash
    streamlit run src/app_ui.py
    ```

3.  Ou execute o Agente no Terminal:
    ```bash
    python src/agent.py
    ```

---

## üß† Arquitetura

1.  **Input do Usu√°rio**: A pergunta entra no sistema.
2.  **Roteador Sem√¢ntico (`classify_intent`)**: O LLM classifica a inten√ß√£o (PROFILE, RISK, HISTORY, etc.).
3.  **Gera√ß√£o de SQL**: Um prompt especializado na inten√ß√£o gera o SQL correto.
4.  **Execu√ß√£o Segura**: O SQL √© executado no `clientatech.db`.
5.  **Analista Persona**: O LLM recebe os dados brutos e gera uma resposta em linguagem natural, formatada especificamente para a inten√ß√£o (ex: Ficha cadastral com emojis, Alerta de Risco, etc.).

## üõ†Ô∏è Tecnologias

*   **Linguagem**: Python
*   **LLM Engine**: Ollama (Local)
*   **Container**: Docker
*   **Frontend**: Streamlit
